{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbotILwUN8Fw"
      },
      "source": [
        "# <font color='00aaff'> **Processo Seletivo Pi Júnior 2024/2** <font/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHJl3vYqOGm5"
      },
      "source": [
        "## <font color='ffffff'> **Python Avançado** <font/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6P4qzQDOQsN"
      },
      "source": [
        "Olá, trainee! Neste arquivo exploraremos uma área um pouco mais avançada do Python, falaremos sobre uma das técnicas mais importantes quando se fala em coleta de dados chamada Web Scraping. Recomendamos que assista a aula de Python avançado da trilha do conhecimento enquanto a acompanha esse documento, para que possa testar por conta própria o que é dito na aula, modificando valores e códigos para ir compreendendo melhor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h54DY9CaQH7a"
      },
      "source": [
        "## <font color='ffffff'> **Definição** <font/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08TfZ1gWRUPZ"
      },
      "source": [
        "Web scraping é o processo de coletar informações de páginas da web de forma automatizada, ou seja, em vez de coletar informações manualmente, é utilizado scripts para navegar pelos elementos de uma página da web e extrair os dados desejados, como texto, imagens, links e muito mais. Essa técnica é muito importante porque permite coletar informações valiosas disponíveis na internet de maneira eficiente e sistemática.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA9s1Z5LUlk8"
      },
      "source": [
        "## <font color='ffffff'> **Site que vamos usar: <a href='https://www.scrapethissite.com/pages/simple/'>**Scrape this site**</a>** <font/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e39GK-pyVjPd"
      },
      "source": [
        "## **1. Inspecionando o site**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Ipvt9NV7L7"
      },
      "source": [
        "O primeiro passo para realizar o Web Scraping é analisar o site que você quer coletar os dados. Basicamente toda informação que existe nele é possível extrair com o Web Scraping (pode ter algumas exceções). Dessa forma, é possível extrair cada texto, link ou imagem de forma automática usando um script.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2xtY_vaV6_Z"
      },
      "source": [
        "### **Primeiro passo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUe7xZWSXjf_"
      },
      "source": [
        "Vamos começar a implementar o código que vamos usar para realizar o Web Scraping. Primeiramente temos que importar a biblioteca que vamos usar, chamada Beautiful Soup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNBu9O_EQybe"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxcVl3hUX8Y5"
      },
      "source": [
        "Após rodar esse código já estará pronto para usar suas funcionalidades\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfIuNhZ-YOyB"
      },
      "source": [
        "### **Segundo Passo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btdoFPFzYRTE"
      },
      "source": [
        "Agora é preciso definir o site que vamos usar e \"baixar\" as informações do site para o código\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj2ajEyZRjwA"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.scrapethissite.com/pages/simple/\"\n",
        "\n",
        "page = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(page.text, \"html.parser\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PG6EmjkYpgi"
      },
      "source": [
        "**Mas que informações são essas?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMxVUvCxaGMp"
      },
      "source": [
        "As informações que usamos do site são as que estão disponíveis no código HTML. Mas não se preocupe, **NÂO** é preciso ter conhecimento de HTML para conseguir coletar as informações\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhEpUYi-ZAtl"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    soup.prettify()[:1400]\n",
        ")  # não se preocupe com esse print, é só pra mostrar uma pequena parte dos dados que são gigantes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iR0vNpnY_3z"
      },
      "source": [
        "**Mas como vou saber onde estão os dados que eu quero?**\n",
        "\n",
        "Não se preocupe, vamos mostrar passo a passo como interpretar esses dados e achar exatamente o que você procura\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HNYZDKCYt6Y"
      },
      "source": [
        "### **Terceiro Passo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDYh0r0Fblyk"
      },
      "source": [
        "Para saber onde está as informações que você procura, vá até o <a href='https://www.scrapethissite.com/pages/simple/'>**site**</a> <font/> e clique no botão direito do mouse, então clique em inspecionar elemento.\n",
        "Com isso você consegue encontrar cada elemento do site e qual sua parte do código correspondente.\n",
        "\n",
        "(_Se estiver com dúvida volte para a video aula novamente e tende entender com a demonstração_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr6QDgCAbmK_"
      },
      "source": [
        "## **2. Usando funções**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nimdAl5BgqKl"
      },
      "source": [
        "As duas principais funções que vamos utilizar são o `soup.find( )` e o `soup.find_all( )`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEk9Pv7fhdTn"
      },
      "source": [
        "A função `soup.find( )` permite encontrar o primeiro elemento correspondente a um determinado critério de pesquisa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKE8TjIghdl-"
      },
      "source": [
        "A construção da função segue o modelo a seguir:\n",
        "\n",
        "`elemento_encontrado = soup.find(nome_do_elemento, atributos)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ausEE33iiH1k"
      },
      "source": [
        "Resumindo:\n",
        "\n",
        "**_nome_do_elemento:_** O nome do elemento HTML que você está procurando (por exemplo, 'div', 'span', 'a').\n",
        "\n",
        "**_atributos:_** Uma lista de atributos e seus valores que você deseja usar para filtrar os elementos (opcional).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EerLSqU32T2G"
      },
      "outputs": [],
      "source": [
        "descricao = soup.find(\"p\", class_=\"lead\").text.strip()\n",
        "# print(descricao)\n",
        "\n",
        "titulo = soup.find(\"h1\").text.strip()\n",
        "print(titulo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD6-Vo__iVcD"
      },
      "source": [
        "### **Exemplo**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m_nkfvioLRP"
      },
      "source": [
        "Para o primeiro exemplo foi buscado a descrição do site que fica logo abaixo do título.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iOPhskVhOAH"
      },
      "outputs": [],
      "source": [
        "# inspecione a página e ache no código o local em que a descrição se encontra\n",
        "\n",
        "descricao = soup.find(\n",
        "    \"p\", class_=\"lead\"\n",
        ")  # perceba que se escreve \"class_\" com o _ no final\n",
        "\n",
        "print(descricao.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSM3VN1Fi0xn"
      },
      "source": [
        "Como pode observar, a exata descrição que aparece no site foi impressa corretamente.\n",
        "\n",
        "Foi utilizado o `.text.strip()` no final apenas para formatar o texto de forma correta, mas você pode tirar essa parte e ver que o dado continua lá, porém apenas sem formatação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYjfxCnqjinx"
      },
      "source": [
        "No exemplo a seguir vamos agora buscar o título da página. Perceba dessa vez que foi utilizado a função duas vezes, isso é algo que também é possível de fazer. Lembre que pode haver vários elementos e classes com o mesmo nome, então tome cuidado e lembre-se que a função `find()` encontra sempre o primeiro elemento com a descrição feita.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5uQ7zH0Mror"
      },
      "outputs": [],
      "source": [
        "titulo = soup.find(\"div\", class_=\"row\")\n",
        "\n",
        "texto = titulo.find(\"h1\").text.strip()\n",
        "\n",
        "print(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP_UQ8aAk78I"
      },
      "source": [
        "Agora sobre a função `find_all()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBcZ0e-HlUCd"
      },
      "source": [
        "A função `find_all()` é uma ferramenta poderosa para encontrar todos os elementos correspondentes a determinados critérios. Ela retorna uma lista de todos os elementos encontrados que correspondem aos critérios de pesquisa especificados.\n",
        "\n",
        "Perceba que essa função **Sempre** retorna uma lista, então para acessar cada elemento vai ser necessário fazer um loop e percorrer cada elemento individualmente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98oBE4KYlt8_"
      },
      "source": [
        "A estrutura é a mesma da função `find()`, ou seja,\n",
        "\n",
        "`elemento_encontrado = soup.find_all(nome_do_elemento, atributos)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRsypTFv3u9S"
      },
      "outputs": [],
      "source": [
        "nome_paises = soup.find_all(\"h3\", class_=\"country-name\")\n",
        "\n",
        "for nome in nome_paises:\n",
        "    print(nome.text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8raipg32llYg"
      },
      "source": [
        "### **Exemplo**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNmqgaA3QofL"
      },
      "outputs": [],
      "source": [
        "nome_paises = soup.find_all(\"h3\", class_=\"country-name\")\n",
        "\n",
        "for nome in nome_paises:\n",
        "    nome = nome.text.strip()\n",
        "    print(nome)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6t4NTK8mJ2W"
      },
      "source": [
        "Nesse caso foi buscado o nome de cada país disponível no site.\n",
        "\n",
        "Perceba que não é possível pegar o texto de cara, é preciso criar um loop para percorrer cada elemento da lista e pegar o nome de cada um individualmente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KVjUicEmfd4"
      },
      "source": [
        "### **Salvando esses dados**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM3xUABdmisd"
      },
      "source": [
        "Usando o `find_all()`, se você deseja salvar esses dados para usá-los de alguma forma posteriormente, você pode criar listas e salvar cada dado desejado em uma lista diferente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8m0yJUum_jY"
      },
      "source": [
        "No exemplo a seguir nós pegamos as informações de cada um daqueles países, sendo elas a Capital, a População e a Area.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaWoShTXwQ9n",
        "outputId": "144ab4c6-7627-4af5-accc-ddd00e4f0734"
      },
      "outputs": [],
      "source": [
        "# achar o local em que todas essas informações estão guardadas\n",
        "dados = soup.find_all(\"div\", class_=\"country-info\")\n",
        "\n",
        "capital = []\n",
        "populacao = []\n",
        "area = []\n",
        "\n",
        "for dado in dados:\n",
        "    capital.append(dado.find(\"span\", class_=\"country-capital\").text.strip())\n",
        "    populacao.append(dado.find(\"span\", class_=\"country-population\").text.strip())\n",
        "    area.append(dado.find(\"span\", class_=\"country-area\").text.strip())\n",
        "\n",
        "print(capital)\n",
        "print(populacao)\n",
        "print(area)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRkreTe30eCD"
      },
      "source": [
        "## **3. Trocando de página**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrelIJMGpCE4"
      },
      "source": [
        "Até agora nós aprendemos a coletar os dados de uma página apenas. Mas e se nós quisermos coletar de várias páginas diferentes?\n",
        "\n",
        "Por exemplo, se a página que eu estiver coletando possui um link para a próxima página, como fazer para pegar os dados dela?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKnPhsyijLgx"
      },
      "source": [
        "Simples! Só é preciso coletar esse link da mesma forma que coletamos os outros dados e chamar a função com o novo url\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOalYdbxjh2F"
      },
      "source": [
        "### **Exemplo, agora com <a href='https://www.scrapethissite.com/pages'>**outra página**</a> <font/>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtJlOXIIj58L"
      },
      "source": [
        "Nessa nova página, nós possuímos alguns textos e links para outras páginas. Se você observar, o primeiro link é a página que estavamos coletando os dados antes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBfTZEjVkSj-"
      },
      "source": [
        "Primeiramente, vamos pegar o link da página manualmente, e depois vamos percorrer as outras páginas de forma automática.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RGudHE10fQl"
      },
      "outputs": [],
      "source": [
        "# selecionando o novo url da página que vamos coletar\n",
        "url2 = \"https://www.scrapethissite.com/pages/\"\n",
        "\n",
        "page2 = requests.get(url2)\n",
        "\n",
        "soup2 = BeautifulSoup(page2.text, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuO4yGR49xrV",
        "outputId": "a5f0672b-d332-47b9-d03f-feccc8f82e57"
      },
      "outputs": [],
      "source": [
        "paginas = soup2.find_all(\"h3\", class_=\"page-title\")\n",
        "todos_links = []\n",
        "\n",
        "for pagina in paginas:\n",
        "    link = pagina.find(\"a\")\n",
        "    nome = link.get(\"href\")\n",
        "    todos_links.append(nome)\n",
        "\n",
        "print(todos_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXk46PUyk0Mn"
      },
      "source": [
        "Agora, da mesma forma que coletamos os dados antes, vamos procurar cada um dos novos links que estão disponíveis na página\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM4AOqme01yC",
        "outputId": "71a2fd69-8fe2-4b13-f252-41b183dfef46"
      },
      "outputs": [],
      "source": [
        "# encontrar onde estão os links\n",
        "paginas = soup2.find_all(\"h3\", class_=\"page-title\")\n",
        "\n",
        "# como usamos o find_all, precisamos guardar os dados em uma lista\n",
        "todos_links = []\n",
        "\n",
        "# usamos um loop para percorrer cada um dos links e salvá-los individualmente\n",
        "for pagina in paginas:\n",
        "    nome = pagina.find(\"a\")[\"href\"]\n",
        "    todos_links.append(nome)\n",
        "\n",
        "print(todos_links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8lh1l6-lPzg"
      },
      "source": [
        "Perceba que no caso desse site temos apenas a extensão que fica no fim do url da página, portanto vamos ter que considerar isso quando formos querer passar para a próxima página. Pode haver casos que o link vai estar completo, então sempre verifique como os dados estão armazenados para usá-los corretamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTCLB4r8AiRw"
      },
      "source": [
        "Perceba que isso gera um pequeno problema, pois se apenas adicionarmos a extensão no final da url que temos, ficamos com um novo link que duplica a parte de \"/pages\", gerando um link incorreto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJjKGru9nfTt",
        "outputId": "248371cc-78be-4d0b-a8d0-851ca0ff5cba"
      },
      "outputs": [],
      "source": [
        "# vamos printar como ficaria os links se apenas adicionarmos as extensões à url que temos\n",
        "for link in todos_links:\n",
        "    novo_url = url2 + link\n",
        "    print(novo_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "246hWc-_BAMM"
      },
      "source": [
        "Para corrigir esse problema, irei usar um método para adicionar apenas parte da extensão para o novo link que vamos gerar, tirando assim a parte \"/pages\" para evitar que se repita no link\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlq9aB2BqNm"
      },
      "source": [
        "Para isso, vamos usar a funcionalidade de python que permite usar apenas parte de um dado, que no nosso caso é um texto que representa a extensão. Para isso, ao invés de usar a variável **link** contendo a extensão inteira, vamos usar **link [7 : ]**, que representa o mesmo dado porém a partir do 7 dígito dele, tirando assim o \"/pages\" que está se repetindo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXYdjmKqBiNs",
        "outputId": "bb97785c-f111-43d9-e6bf-9b87abec9ab1"
      },
      "outputs": [],
      "source": [
        "# adicionar as extensões aos links após a correção\n",
        "for link in todos_links:\n",
        "    url_correto = url2 + link[7:]\n",
        "    print(url_correto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2j0J66OnIHu"
      },
      "source": [
        "Agora que temos todas as extensões corretamente em uma lista, basta criar um loop e fazer todo o processo inicial de pegar a url e coletar os dados para cada um dos links que nós salvamos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRm6TwTvFMI6"
      },
      "source": [
        "Perceba que vai gerar um erro nesse código, mas é intencional e ainda sim vai imprimir os resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4Iehk-k2o10"
      },
      "outputs": [],
      "source": [
        "# loop que vai pegar cada url, fazer a correção como mostrado anteriormente e depois coletar dados de cada página que visitar\n",
        "\n",
        "for link in todos_links:\n",
        "    novo_url = url2 + link[7:]\n",
        "    print(\"site visitado:  \", novo_url)\n",
        "\n",
        "    # fazer os passos iniciais para coletar as informações da página\n",
        "    nova_pagina = requests.get(novo_url)\n",
        "    novo_soup = BeautifulSoup(nova_pagina.text, \"html.parser\")\n",
        "\n",
        "    # procurar o elemento que queremos coletar, nesse caso estamos pegando o título\n",
        "    novo_titulo = novo_soup.find(\"div\", class_=\"row\")\n",
        "\n",
        "    novo_texto = novo_titulo.find(\"h1\").text.strip()\n",
        "\n",
        "    print(\"dado coletado:  \", novo_texto)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HTWMbxBFUhB"
      },
      "source": [
        "O erro foi gerado na última página que ele estava fazendo a coleta, mas por que isso aconteceu?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZKyLWgAFZnI"
      },
      "source": [
        "Lembre-se sempre de analisar cuidadosamente os dados que você está querendo coletar. Em todos os primeiros sites que ele coleta as informações o título da página está no elemento **h1**, porém no último site em que foi gerado o erro, o título está no elemento **h3**, não encontrando assim a informação que procurava e gerando um erro.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5bY-wJRGBE-"
      },
      "source": [
        "Por isso sempre esteja atento tanto na estrutura do site quanto nos códigos que você escreve, sempre haverá desafios diferentes e é sua função encontrá-los e descobrir uma solução.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQfAcFNl6hf7"
      },
      "source": [
        "# **4. Funcões select e select_one**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dirHVSlU6t70"
      },
      "source": [
        "Por fim, falaremos a respeito de duas funções que, apesar de serem menos utitizadas no geral, possuem sua importância e podem ser usadas como poderosas ferramentas para acessar dados mais especificos ou profundos dentro do codigo HTML.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex-iTHgt7s32"
      },
      "source": [
        "Estamos falando das funções `select()` e `select_one()`. Elas funcionam como buscadores assim como o find, mas ao inves de receber como argumentos tags HTML ela recebe seletores CSS diretamente. Abaixo será mostrada a sintaxe basica da função select_one, que é equivalente à função find:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8slEv84OCTtt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqqMU2X2CRih"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ZMrih78bfA"
      },
      "source": [
        "`elemento_encontrado = soup.select_one(seletor_css)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBD_k-TK86ax"
      },
      "source": [
        "# **Exemplo:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W23rzidw8_3R"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.scrapethissite.com/pages/simple/\"\n",
        "resposta = requests.get(url)\n",
        "soup = BeautifulSoup(resposta.text, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6utCjHE9FD2",
        "outputId": "ecb1f5f0-11c0-47a6-eeee-67e6885089e0"
      },
      "outputs": [],
      "source": [
        "titulo = soup.select_one(\"h1\").text.strip()\n",
        "\n",
        "print(titulo)\n",
        "\n",
        "descricao = soup.select_one(\"p.lead\").text.strip()\n",
        "print(descricao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58fartd3B7zM"
      },
      "source": [
        "Como pode ser observado, a principal diferença se da no argumento recebido pela funcao. Ao inves de escrever da forma `(tag, atributo=\"\")`, escreve-se da forma `(\"tag.atributo\")` nesse caso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwSRcpPUCU8b"
      },
      "source": [
        "Agora falando da função `select(`). Ela, asism como a funcao `find_all()`, retorna uma lista dos elementos que corresponderem aos argumentos passados dentro do codigo HTML, e possui a mesma sintaxe que a função `select_one()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4J3m0cuCz2N"
      },
      "outputs": [],
      "source": [
        "dados = soup.select(\"div.country-info\")\n",
        "\n",
        "capital = []\n",
        "populacao = []\n",
        "area = []\n",
        "\n",
        "for dado in dados:\n",
        "    capital.append(dado.select_one(\"span.country-capital\").text.strip())\n",
        "    populacao.append(dado.select_one(\"span.country-population\").text.strip())\n",
        "    area.append(dado.select_one(\"span.country-area\").text.strip())\n",
        "\n",
        "print(capital)\n",
        "print(populacao)\n",
        "print(area)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_lkU3hh1pGM"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDmseBBEEGbv"
      },
      "source": [
        "Uma questao importante é sobre como acessar os diferentes seletores CSS. Abaixo serão listados os principais:\n",
        "\n",
        "**Selecionar por Tag:**\n",
        "h1 seleciona todas as tags h1.\n",
        "\n",
        "**Selecionar por Classe:**\n",
        ".country-name seleciona todos os elementos com class=\"country-name\".\n",
        "\n",
        "**Selecionar por ID:**\n",
        "(#hashtag)main-header seleciona o elemento com id=\"main-header\".\n",
        "\n",
        "**Combinando Tag e Classe:**\n",
        "\n",
        "h3.country-name seleciona todas as h3 com class=\"country-name\".\n",
        "\n",
        "**Seleção Hierárquica:**\n",
        "div.country h3.country-name seleciona h3 class=\"country-name\"> dentro de div class=\"country\".\n",
        "\n",
        "**Selecionar por Atributo:**\n",
        "a[href=\"https://example.com\"] seleciona a com href específico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EOEYcU7H1dk"
      },
      "source": [
        "Outro aspecto relevante é sobre como funciona a hierarquia dos seletores CSS e como podemos usar ele a nosso favor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WgFjKvCIDcC"
      },
      "source": [
        "# **Exemplo:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ1RLxWbIGND",
        "outputId": "a53fe569-bffd-4308-d46f-060cde180a86"
      },
      "outputs": [],
      "source": [
        "capital = soup.select_one(\n",
        "    \"div.country div.country-info span.country-capital\"\n",
        ").text.strip()\n",
        "\n",
        "print(capital)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN-EwLlKJv8-"
      },
      "source": [
        "Como é possível ver, a hierarquia pode ser explorada no sentido de que pode-se chamar tags que pertencem à outras tags dando um espaço entre elas. Há outros operadores mais específicos mas no geral eles nao precisam ser usados. Isso permite acessar atributos mais específicos de uma maneira mais simples e prática\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-i0JKzZGqK2"
      },
      "source": [
        "## **5. Exercícios**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYkO8q4jGobI"
      },
      "source": [
        "Agora é sua vez de praticar, tente coletar algumas informações do website a seguir para praticar o que aprendeu.\n",
        "\n",
        "Não se preocupe, esse site é bem mais simples e com menos informações!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK97FOX8H1Zo"
      },
      "source": [
        "O site que utilizaremos é o <a href='https://quotes.toscrape.com'>**Quotes to Scrape**</a> <font/>, é um site bem simples que possui citações de várias pessoas famosas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u07H4KyXG48m"
      },
      "source": [
        "### **Exercício 1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE69p2zMHXI2"
      },
      "source": [
        "Escreva um código para coletar a citação em si e o nome do autor da primeira citação que aparece no site. _Lembre-se dos primeiros passos para inicialmente baixar todas as informações do site._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj4_hvWCIy-P"
      },
      "source": [
        "Lembre-se de usar o `.text.strip()` para formatar o seu dado para que seja retornado apenas o texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRaB2y7zIvEF"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://quotes.toscrape.com\"\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.text, \"html\")\n",
        "\n",
        "print(soup.find(\"span\", class_=\"text\").text.strip())\n",
        "print(soup.find(\"small\", class_=\"author\").text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPMBLhPNK390"
      },
      "source": [
        "### **Exercício 2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EisoK2EJJHIx"
      },
      "source": [
        "Colete agora todas as citações e os nomes dos autores que estão na primeira página do site. Para isso vai ser necessário criar uma lista pra cada e salvar os dados respectivos em cada lista.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VifyqJq7MzUX"
      },
      "source": [
        "Lembre-se que é possível usar o text to strip dentro do loop para melhorar a formatação dos dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFuidccyMJzm"
      },
      "outputs": [],
      "source": [
        "caixas = soup.find_all(\"div\", class_=\"quote\")\n",
        "\n",
        "citacoes = []\n",
        "autores = []\n",
        "\n",
        "for caixa in caixas:\n",
        "    citacoes.append(caixa.find(\"span\", class_=\"text\").text.strip())\n",
        "    autores.append(caixa.find(\"small\", class_=\"author\").text.strip())\n",
        "\n",
        "print(citacoes)\n",
        "print(autores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
